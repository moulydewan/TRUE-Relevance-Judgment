{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "system_message = \"\"\"Please assess how well the provided passage meets the **RUBRICS** criteria in relation to the query.\n",
    "Use the following scoring scale (0-3) and strictly use the following RUBRICS for evaluation:\n",
    "0: Not relevant at all\n",
    "1: Marginally relevant\n",
    "2: Fairly relevant\n",
    "3: Highly relevant\n",
    "\n",
    "**RUBRICS**\n",
    "\n",
    "Your evaluation must be based on the following five dimensions:\n",
    "A. Intent Alignment – how well the passage matches the user’s underlying query intent.\n",
    "B. Coverage – how fully the passage addresses the information need (breadth and depth).\n",
    "C. Specificity – how precise, focused and contextually connected the passage is to the query.\n",
    "D. Accuracy – whether the information is factually correct, reliable and not misleading.\n",
    "E. Usefulness – whether the passage would actually help the user achieve their goal or stop searching.\n",
    "\n",
    "**Assign scores STRICTLY based on the following rubric:**\n",
    "\n",
    "Assign Score 0 if:\n",
    "- Intent Alignment: No alignment, completely off-topic. (primarily navigation, category dumps, ads, link hubs, or template chrome with no substantive answer content.)\n",
    "- Coverage: No meaningful information for the query.\n",
    "- Specificity: May contain keywords but lacks contextual connection.\n",
    "- Accuracy: Incorrect, irrelevant or misleading.\n",
    "- Usefulness: Totally useless for the query.\n",
    "\n",
    "Assign Score 1 if:\n",
    "- Intent Alignment: Partailly, content is relevant but primarily discusses something else.\n",
    "- Coverage: Very limited; misses major aspects of the need.\n",
    "- Specificity: General statements or vague mentions without detail.\n",
    "- Accuracy: Information may be correct but not applied to the query.\n",
    "- Usefulness: Slightly helpful but insufficient for the query.\n",
    "\n",
    "Assign Score 2 if:\n",
    "- Intent Alignment: Addresses the main intent but not detailed.\n",
    "- Coverage: Provides adequate but incomplete information (some gaps remain).\n",
    "- Specificity: On-topic and somewhat detailed, but not comprehensive.\n",
    "- Accuracy: Generally correct and reliable.\n",
    "- Usefulness: Helps the query somewhat, but more information is needed.\n",
    "\n",
    "Assign Score 3 if:\n",
    "- Intent Alignment: Fully aligned with the user’s query intent.\n",
    "- Coverage: Comprehensive, detailed and addressing all major aspects directly.\n",
    "- Specificity: Precise, detailed, and contextually rich.\n",
    "- Accuracy: Factually correct, authoritative, and trustworthy.\n",
    "- Usefulness: Strongly satisfies the query need; no further search is required.\n",
    "\n",
    "Final score must be an integer value only. Do not provide any reasoning and code in result. Only provide each score in the format of integer 0, 1, 2, or 3.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_prompt(query, passage):\n",
    "    return f\"\"\"Please rate how the given passage is relevant to the query strictly based on the rubrics. The output score must be only an integer that indicate how relevant they are.\n",
    "\n",
    "    Query: {query}\n",
    "    Passage: {passage}\n",
    "    Score:\"\"\"\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
