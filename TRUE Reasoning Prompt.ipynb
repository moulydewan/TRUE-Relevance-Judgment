{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "system_message = \"\"\"Please assess how well the provided passage meets the **RUBRICS** criteria in relation to the query.\n",
    "Use the following scoring scale (0-3) and strictly use the following RUBRICS for evaluation:\n",
    "0: Not relevant at all\n",
    "1: Marginally relevant\n",
    "2: Fairly relevant\n",
    "3: Highly relevant\n",
    "\n",
    "**RUBRICS**\n",
    "\n",
    "Your evaluation must be based on the following five dimensions:\n",
    "A. Intent Alignment – how well the passage matches the user’s underlying query intent.\n",
    "B. Coverage – how fully the passage addresses the information need (breadth and depth).\n",
    "C. Specificity – how precise, focused and contextually connected the passage is to the query.\n",
    "D. Accuracy – whether the information is factually correct, reliable and not misleading.\n",
    "E. Usefulness – whether the passage would actually help the user achieve their goal or stop searching.\n",
    "\n",
    "**Assign scores STRICTLY based on the following rubric:**\n",
    "\n",
    "Assign Score 0 if:\n",
    "- Intent Alignment: No alignment with the query main subject. Passage might look like its explaining the query but the query subject is not explicitly mentioned.\n",
    "- Coverage: Related information but no meaningful information for the query subject.\n",
    "- Specificity: May contain keywords from query but its talking about a different subject.\n",
    "- Accuracy: Information is irrelevant for the query subject.\n",
    "- Usefulness: Useless for the query.\n",
    "\n",
    "Assign Score 1 if:\n",
    "- Intent Alignment: Marginal alignment, content is relevant but primarily discusses something else.\n",
    "- Coverage: Limited information to the query; misses major aspects of the query.\n",
    "- Specificity: General statements or vague mentions without detail.\n",
    "- Accuracy: Information may be correct but not applied to the query.\n",
    "- Usefulness: Slightly helpful but insufficient for the query.\n",
    "\n",
    "Assign Score 2 if:\n",
    "- Intent Alignment: Mostly addresses the main query intent but not detailed.\n",
    "- Coverage: Provides information to the query and mostly covers main intent.\n",
    "- Specificity: Addresses query and somewhat detailed, but not comprehensive.\n",
    "- Accuracy: Partially correct and reliable to the query.\n",
    "- Usefulness: Helps the query, but more information is needed.\n",
    "\n",
    "Assign Score 3 if:\n",
    "- Intent Alignment: Fully aligned with the user’s query intent.\n",
    "- Coverage: Comprehensive, detailed and addressing all major aspects directly.\n",
    "- Specificity: Precise, detailed, and contextually rich.\n",
    "- Accuracy: Factually correct and trustworthy.\n",
    "- Usefulness: Strongly satisfies the query need; no further search is required.\n",
    "\n",
    "\n",
    "Final score must be an integer value only. Provide reasoning for the dimensions for the score.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_prompt(query, passage):\n",
    "    return f\"\"\"Please rate how the given passage is relevant to the query strictly based on the rubrics. \n",
    "    Take a step back and provide reasoning with the rubrics. The output score must be only an integer that indicate how relevant they are.\n",
    "\n",
    "    Query: {query}\n",
    "    Passage: {passage}\n",
    "    Score:\n",
    "    Reasoning:\"\"\"\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
